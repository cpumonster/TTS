import React, { useState, useCallback, useEffect } from 'react';
import type { Persona, AudioData } from '../types';
import { generateAnalyticalScript, generateSpeech, generateConversationSpeech, optimizeScriptForPodcast } from '../services/geminiService';
import { IconSparkles, IconAudio, IconChat, IconDownload } from './Icons';
import { downloadText, downloadAudio, createTimestamp } from '../utils/download';

interface ScriptingStudioProps {
  researchData: string;
  podcastScript: string;
  setPodcastScript: (script: string) => void;
  personas: Persona[];
  audioData: AudioData;
  setAudioData: (data: AudioData) => void;
  setIsLoading: (loading: boolean) => void;
  setLoadingMessage: (message: string) => void;
  toast: ReturnType<typeof import('../hooks/useToast').useToast>;
}

// Helper function to write a string to a DataView
function writeString(view: DataView, offset: number, string: string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}

/**
 * Creates a valid WAV file Blob from raw PCM audio data.
 * The Gemini TTS API returns audio as 1-channel, 24000Hz, 16-bit PCM.
 * @param pcmData The raw PCM audio data as a Uint8Array.
 * @returns A Blob representing a valid WAV file.
 */
function createWavBlob(pcmData: Uint8Array): Blob {
    const sampleRate = 24000;
    const numChannels = 1;
    const bitsPerSample = 16;
    const dataSize = pcmData.length;
    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);

    // RIFF chunk descriptor
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true); // chunkSize
    writeString(view, 8, 'WAVE');

    // "fmt " sub-chunk
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true); // subchunk1Size (16 for PCM)
    view.setUint16(20, 1, true); // audioFormat (1 for PCM)
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * (bitsPerSample / 8), true); // byteRate
    view.setUint16(32, numChannels * (bitsPerSample / 8), true); // blockAlign
    view.setUint16(34, bitsPerSample, true);

    // "data" sub-chunk
    writeString(view, 36, 'data');
    view.setUint32(40, dataSize, true);

    // Write PCM data
    new Uint8Array(buffer).set(pcmData, 44);

    return new Blob([buffer], { type: 'audio/wav' });
}


const AudioPlayer: React.FC<{ persona: Persona; audio?: AudioData[string] }> = ({ persona, audio }) => {
  return (
    <div className="bg-gray-800 p-4 rounded-lg flex items-center space-x-4">
      <img src={persona.avatar} alt={persona.name} className="w-12 h-12 rounded-full" />
      <div className="flex-grow">
        <p className="font-semibold">{persona.name}</p>
        {audio ? (
          <audio controls src={audio.url} className="w-full h-8 mt-1" />
        ) : (
          <div className="w-full h-8 mt-1 bg-gray-700 rounded-md flex items-center justify-center">
            <p className="text-xs text-gray-400">Audio not generated</p>
          </div>
        )}
      </div>
    </div>
  );
};

const ConversationPlayer: React.FC<{ audio?: AudioData[string] }> = ({ audio }) => {
    return (
      <div className="bg-gray-800 p-4 rounded-lg border border-purple-500/50">
        <div className="flex items-center space-x-4">
          <div className="bg-purple-500 rounded-full p-3">
            <IconChat className="w-6 h-6 text-white" />
          </div>
          <div className="flex-grow">
            <div className="flex items-center justify-between">
              <p className="font-semibold text-purple-300">Full Conversation (Podcast)</p>
              {audio && (
                <button
                  onClick={() => downloadAudio(audio.url, `podcast-${createTimestamp()}.wav`)}
                  className="flex items-center px-2 py-1 text-xs bg-purple-600 hover:bg-purple-700 rounded-md transition-colors"
                  title="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ"
                >
                  <IconDownload className="w-3 h-3 mr-1" />
                  ë‹¤ìš´ë¡œë“œ
                </button>
              )}
            </div>
            {audio ? (
              <audio controls src={audio.url} className="w-full h-8 mt-1" />
            ) : (
              <div className="w-full h-8 mt-1 bg-gray-700 rounded-md flex items-center justify-center">
                <p className="text-xs text-gray-400">Generate speech to listen</p>
              </div>
            )}
          </div>
        </div>
      </div>
    );
  };

export const ScriptingStudio: React.FC<ScriptingStudioProps> = ({
  researchData, podcastScript, setPodcastScript, personas, audioData, setAudioData, setIsLoading, setLoadingMessage, toast
}) => {
  const [conversationAudio, setConversationAudio] = useState<AudioData[string] | null>(null);
  const [editableScript, setEditableScript] = useState<string>('');
  
  useEffect(() => {
    setEditableScript(podcastScript);
  }, [podcastScript]);

  const handleGenerateScript = useCallback(async () => {
    if (!researchData) {
        toast.warning("ë¨¼ì € 1ë‹¨ê³„ì—ì„œ ë¦¬ì„œì¹˜ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.");
        return;
    }
    setIsLoading(true);
    setLoadingMessage('TTS ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    try {
      const optimized = await generateAnalyticalScript(researchData);
      setPodcastScript(optimized);
      setEditableScript(optimized);
      toast.success('ìŠ¤í¬ë¦½íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!');
    } catch (error) {
      toast.error(error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsLoading(false);
    }
  }, [researchData, setPodcastScript, setIsLoading, setLoadingMessage, toast]);

  const handleOptimizeScript = useCallback(async () => {
    if (!editableScript) {
        toast.warning("ë¨¼ì € ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.");
        return;
    }
    setIsLoading(true);
    setLoadingMessage('íŒŸìºìŠ¤íŠ¸ ì „ë‹¬ì— ìµœì í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    try {
        const optimized = await optimizeScriptForPodcast(editableScript, (attempt) => {
          setLoadingMessage(`ìµœì í™” ì¬ì‹œë„ ì¤‘... (${attempt}ë²ˆì§¸ ì‹œë„)`);
        });
        setEditableScript(optimized);
        toast.success('ìŠ¤í¬ë¦½íŠ¸ ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!');
    } catch (error) {
        toast.error(error instanceof Error ? error.message : 'ìµœì í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
        setIsLoading(false);
    }
  }, [editableScript, setIsLoading, setLoadingMessage, toast]);

  const handleGenerateAudio = useCallback(async () => {
    if (!editableScript) {
        toast.warning("ë¨¼ì € ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.");
        return;
    }
    
    console.warn('ğŸ¤ =========================');
    console.warn('ğŸ™ï¸ GEMINI TTS GENERATION');
    console.warn('=========================');
    console.warn('Using: Gemini API (generateContent)');
    console.warn('Model: gemini-2.5-flash-preview-tts');
    console.warn('Script length:', editableScript.length);
    
    setIsLoading(true);
    setLoadingMessage('Gemini TTSë¡œ ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    setConversationAudio(null);
    setAudioData({});
    
    try {
      // ì „ì²´ ëŒ€í™” ìŒì„± ìƒì„± (multiSpeakerVoiceConfig ì‚¬ìš©)
      setLoadingMessage('ì „ì²´ ëŒ€í™” íŠ¸ë™ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
      
      try {
        console.warn('ğŸ™ï¸ Step 1/3: Generating multi-speaker conversation...');
        const conversationBase64 = await generateConversationSpeech(editableScript, personas, (attempt) => {
          setLoadingMessage(`ëŒ€í™” íŠ¸ë™ ì¬ì‹œë„ ì¤‘... (${attempt}ë²ˆì§¸ ì‹œë„)`);
        });
        
        if (conversationBase64) {
          const rawPcmData = Uint8Array.from(atob(conversationBase64), c => c.charCodeAt(0));
          const audioBlob = createWavBlob(rawPcmData);
          const audioUrl = URL.createObjectURL(audioBlob);
          setConversationAudio({ url: audioUrl, waveform: [] });
          console.warn('âœ… Conversation audio created');
        }
        
        // API ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸° ì‹œê°„ (FlashëŠ” ë¹ ë¥´ë¯€ë¡œ ì§§ê²Œ)
        console.warn('â³ Waiting 2 seconds to avoid API overload...');
        await new Promise(resolve => setTimeout(resolve, 2000));
        
      } catch (e) {
        const errorMessage = e instanceof Error ? e.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
        console.error('âŒ Failed to generate conversation audio', e);
        toast.error(`ëŒ€í™” ìŒì„± ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
      }

      // ê°œë³„ í™”ì ìŒì„± ìƒì„± (ìˆœì°¨ì ìœ¼ë¡œ)
      const newAudioData: AudioData = {};
      let hasErrors = false;
      
      for (let i = 0; i < personas.length; i++) {
        const persona = personas[i];
        setLoadingMessage(`${persona.name} ê°œë³„ ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (${i + 1}/${personas.length})`);
        
        try {
          console.warn(`ğŸ¤ Step ${i + 2}/3: Generating speech for ${persona.name}...`);
          const base64Audio = await generateSpeech(editableScript, persona, (attempt) => {
            setLoadingMessage(`${persona.name} ì¬ì‹œë„ ì¤‘... (${attempt}ë²ˆì§¸ ì‹œë„)`);
          });
          
          if (base64Audio) {
            const rawPcmData = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));
            const audioBlob = createWavBlob(rawPcmData);
            const audioUrl = URL.createObjectURL(audioBlob);
            newAudioData[persona.id] = { url: audioUrl, waveform: [] };
            console.warn(`âœ… Individual audio created for ${persona.name}`);
          }
          
          // ë‹¤ìŒ ìš”ì²­ ì „ ëŒ€ê¸° (ë§ˆì§€ë§‰ personaê°€ ì•„ë‹Œ ê²½ìš°) - FlashëŠ” ë¹ ë¥´ë¯€ë¡œ ì§§ê²Œ
          if (i < personas.length - 1) {
            console.warn('â³ Waiting 1 second before next request...');
            await new Promise(resolve => setTimeout(resolve, 1000));
          }
          
        } catch (e) {
          const errorMessage = e instanceof Error ? e.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
          toast.error(`${persona.name} ìŒì„± ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
          console.error(`Failed to generate audio for ${persona.name}`, e);
          hasErrors = true;
        }
      }
      
      setAudioData(newAudioData);

      console.warn('=========================');
      console.warn('âœ… Audio generation completed');
      console.warn('=========================');

      if (!hasErrors) {
        toast.success('ëª¨ë“  ì˜¤ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!');
      }

    } catch (error) {
      toast.error(error instanceof Error ? error.message : 'ì˜¤ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsLoading(false);
    }
  }, [editableScript, personas, setAudioData, setIsLoading, setLoadingMessage, toast]);

  // ì „ì²´ ëŒ€í™” ìŒì„± ìƒì„± (Multi-speaker) - ë³„ë„ ë²„íŠ¼
  const handleGenerateConversation = useCallback(async () => {
    if (!editableScript) {
        toast.warning("ë¨¼ì € ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.");
        return;
    }
    
    console.warn('ğŸ™ï¸ =========================');
    console.warn('ğŸ™ï¸ MULTI-SPEAKER GENERATION');
    console.warn('=========================');
    console.warn('Model: gemini-2.5-flash-preview-tts (ì•ˆì •ì„± ìš°ì„ )');
    console.warn('Script length:', editableScript.length);
    console.warn('âš ï¸ Note: Multi-speakerëŠ” Flash ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (Pro ëª¨ë¸ì€ ë¶ˆì•ˆì •).');
    
    setIsLoading(true);
    setLoadingMessage('Flash ëª¨ë¸ë¡œ ì „ì²´ ëŒ€í™” íŠ¸ë™ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ìµœëŒ€ 8ë¶„ ì†Œìš”)');
    setConversationAudio(null);
    
    try {
      const conversationBase64 = await generateConversationSpeech(editableScript, personas, (attempt) => {
        setLoadingMessage(`ëŒ€í™” íŠ¸ë™ ì¬ì‹œë„ ì¤‘... (${attempt}ë²ˆì§¸ ì‹œë„)`);
      });
      
      if (conversationBase64) {
        const rawPcmData = Uint8Array.from(atob(conversationBase64), c => c.charCodeAt(0));
        const audioBlob = createWavBlob(rawPcmData);
        const audioUrl = URL.createObjectURL(audioBlob);
        setConversationAudio({ url: audioUrl, waveform: [] });
        console.warn('âœ… Multi-speaker conversation created');
        toast.success('ì „ì²´ ëŒ€í™” ìŒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!');
      }
    } catch (e) {
      const errorMessage = e instanceof Error ? e.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      console.error('âŒ Failed to generate conversation audio', e);
      toast.error(`ëŒ€í™” ìŒì„± ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
    } finally {
      setIsLoading(false);
      setLoadingMessage('');
    }
  }, [editableScript, personas, setIsLoading, setLoadingMessage, toast]);

  // Q (ìŠ¤í”¼ì»¤1) ìŒì„± ìƒì„± - ê°œë³„ ë²„íŠ¼
  const handleGenerateQVoice = useCallback(async () => {
    if (!editableScript) {
        toast.warning("ë¨¼ì € ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.");
        return;
    }
    
    const qPersona = personas.find(p => p.id === 'q');
    if (!qPersona) {
        toast.error("Q ë¶„ì„ê°€ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
    }
    
    // Qì˜ ëŒ€ì‚¬ë§Œ ì¶”ì¶œ
    const lines = editableScript.split('\n');
    const qLines: string[] = [];
    let isQSpeaking = false;
    
    for (const line of lines) {
      if (line.startsWith('Q:') || line.startsWith('Q (Analyst):')) {
        isQSpeaking = true;
        // í™”ì ë ˆì´ë¸”ê³¼ ë”°ì˜´í‘œ ì œê±°í•˜ê³  ëŒ€ì‚¬ë§Œ ì¶”ê°€
        const dialogue = line
          .replace(/^Q(\s*\(Analyst\))?:\s*/, '')
          .replace(/^["']|["']$/g, '') // ì‹œì‘ê³¼ ëì˜ ë”°ì˜´í‘œ ì œê±°
          .trim();
        if (dialogue) qLines.push(dialogue);
      } else if (line.startsWith('ì§€ì˜:') || line.startsWith('ì§€ì˜ (Host):')) {
        isQSpeaking = false;
      } else if (isQSpeaking && line.trim()) {
        // ì—°ì†ëœ Qì˜ ëŒ€ì‚¬ (ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ ê²½ìš°)
        qLines.push(line.trim());
      }
    }
    
    const qOnlyScript = qLines.join(' '); // ê°œí–‰ ëŒ€ì‹  ê³µë°±ìœ¼ë¡œ ì—°ê²° (ë” ìì—°ìŠ¤ëŸ¬ìš´ íë¦„)
    
    if (!qOnlyScript || qOnlyScript.trim().length === 0) {
        toast.error("Qì˜ ëŒ€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
        console.error('No Q dialogues found in script');
        return;
    }
    
    console.warn('ğŸ¤ =========================');
    console.warn('ğŸ¤ Q (ANALYST) VOICE GENERATION');
    console.warn('=========================');
    console.warn('Model: gemini-2.5-flash-preview-tts');
    console.warn('Speaker:', qPersona.name);
    console.warn('Voice:', qPersona.voiceId);
    console.warn('Original script length:', editableScript.length);
    console.warn('Q-only script length:', qOnlyScript.length);
    console.warn('Q lines count:', qLines.length);
    console.warn('âœ… Note: ê°ì • íƒœê·¸ í¬í•¨ (ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±)');
    console.warn('Q script preview (first 300 chars):', qOnlyScript.substring(0, 300));
    
    setIsLoading(true);
    setLoadingMessage('Q ë¶„ì„ê°€ ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    
    try {
      const base64Audio = await generateSpeech(qOnlyScript, qPersona, (attempt) => {
        setLoadingMessage(`Q ìŒì„± ì¬ì‹œë„ ì¤‘... (${attempt}ë²ˆì§¸ ì‹œë„)`);
      });
      
      if (base64Audio) {
        const rawPcmData = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));
        const audioBlob = createWavBlob(rawPcmData);
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudioData(prev => ({ ...prev, q: { url: audioUrl, waveform: [] } }));
        console.warn('âœ… Successfully generated Q voice');
        toast.success("Q ë¶„ì„ê°€ ìŒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!");
      } else {
        throw new Error('No audio data received');
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      console.error('Q voice generation error:', error);
      toast.error(`Q ìŒì„± ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
    } finally {
      setIsLoading(false);
      setLoadingMessage('');
    }
  }, [editableScript, personas, setAudioData, setIsLoading, setLoadingMessage, toast]);

  // ì§€ì˜ (ìŠ¤í”¼ì»¤2) ìŒì„± ìƒì„± - ê°œë³„ ë²„íŠ¼
  const handleGenerateJiyoungVoice = useCallback(async () => {
    if (!editableScript) {
        toast.warning("ë¨¼ì € ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.");
        return;
    }
    
    const jiyoungPersona = personas.find(p => p.id === 'jiyoung');
    if (!jiyoungPersona) {
        toast.error("ì§€ì˜ í˜¸ìŠ¤íŠ¸ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
    }
    
    // ì§€ì˜ì˜ ëŒ€ì‚¬ë§Œ ì¶”ì¶œ
    const lines = editableScript.split('\n');
    const jiyoungLines: string[] = [];
    let isJiyoungSpeaking = false;
    
    for (const line of lines) {
      if (line.startsWith('ì§€ì˜:') || line.startsWith('ì§€ì˜ (Host):')) {
        isJiyoungSpeaking = true;
        // í™”ì ë ˆì´ë¸”ê³¼ ë”°ì˜´í‘œ ì œê±°í•˜ê³  ëŒ€ì‚¬ë§Œ ì¶”ê°€
        const dialogue = line
          .replace(/^ì§€ì˜(\s*\(Host\))?:\s*/, '')
          .replace(/^["']|["']$/g, '') // ì‹œì‘ê³¼ ëì˜ ë”°ì˜´í‘œ ì œê±°
          .trim();
        if (dialogue) jiyoungLines.push(dialogue);
      } else if (line.startsWith('Q:') || line.startsWith('Q (Analyst):')) {
        isJiyoungSpeaking = false;
      } else if (isJiyoungSpeaking && line.trim()) {
        // ì—°ì†ëœ ì§€ì˜ì˜ ëŒ€ì‚¬ (ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ ê²½ìš°)
        jiyoungLines.push(line.trim());
      }
    }
    
    const jiyoungOnlyScript = jiyoungLines.join(' '); // ê°œí–‰ ëŒ€ì‹  ê³µë°±ìœ¼ë¡œ ì—°ê²° (ë” ìì—°ìŠ¤ëŸ¬ìš´ íë¦„)
    
    if (!jiyoungOnlyScript || jiyoungOnlyScript.trim().length === 0) {
        toast.error("ì§€ì˜ì˜ ëŒ€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
        console.error('No ì§€ì˜ dialogues found in script');
        return;
    }
    
    console.warn('ğŸ¤ =========================');
    console.warn('ğŸ¤ ì§€ì˜ (HOST) VOICE GENERATION');
    console.warn('=========================');
    console.warn('Model: gemini-2.5-flash-preview-tts');
    console.warn('Speaker:', jiyoungPersona.name);
    console.warn('Voice:', jiyoungPersona.voiceId);
    console.warn('Original script length:', editableScript.length);
    console.warn('ì§€ì˜-only script length:', jiyoungOnlyScript.length);
    console.warn('ì§€ì˜ lines count:', jiyoungLines.length);
    console.warn('âœ… Note: ê°ì • íƒœê·¸ í¬í•¨ (ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±)');
    console.warn('ì§€ì˜ script preview (first 300 chars):', jiyoungOnlyScript.substring(0, 300));
    
    setIsLoading(true);
    setLoadingMessage('ì§€ì˜ í˜¸ìŠ¤íŠ¸ ìŒì„±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    
    try {
      const base64Audio = await generateSpeech(jiyoungOnlyScript, jiyoungPersona, (attempt) => {
        setLoadingMessage(`ì§€ì˜ ìŒì„± ì¬ì‹œë„ ì¤‘... (${attempt}ë²ˆì§¸ ì‹œë„)`);
      });
      
      if (base64Audio) {
        const rawPcmData = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));
        const audioBlob = createWavBlob(rawPcmData);
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudioData(prev => ({ ...prev, jiyoung: { url: audioUrl, waveform: [] } }));
        console.warn('âœ… Successfully generated ì§€ì˜ voice');
        toast.success("ì§€ì˜ í˜¸ìŠ¤íŠ¸ ìŒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!");
      } else {
        throw new Error('No audio data received');
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      console.error('ì§€ì˜ voice generation error:', error);
      toast.error(`ì§€ì˜ ìŒì„± ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
    } finally {
      setIsLoading(false);
      setLoadingMessage('');
    }
  }, [editableScript, personas, setAudioData, setIsLoading, setLoadingMessage, toast]);

  return (
    <div className="space-y-6 h-full">
        <div>
            <h2 className="text-2xl font-bold text-purple-400 mb-2">2. Script Generation & Refinement</h2>
            <p className="text-gray-400 mb-4">ë¦¬ì„œì¹˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ 3ë¶„ ë¶„ì„ íŒŸìºìŠ¤íŠ¸ TTS Pro ìµœì í™” ëŒ€ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤.</p>
        </div>

        <div className="bg-gray-800/50 p-4 rounded-lg">
            <h3 className="text-lg font-semibold mb-2">Research Data</h3>
            <div className="max-h-32 overflow-y-auto bg-gray-900/50 p-2 rounded-md border border-gray-700">
                <pre className="whitespace-pre-wrap text-sm text-gray-300 font-sans">
                    {researchData || "No research data from Step 1."}
                </pre>
            </div>
            <button 
                onClick={handleGenerateScript} 
                disabled={!researchData}
                className="mt-4 w-full flex items-center justify-center px-4 py-2 font-semibold bg-purple-600 rounded-md hover:bg-purple-700 transition-colors disabled:bg-gray-600 disabled:cursor-not-allowed"
            >
                <IconSparkles className="w-5 h-5 mr-2" />
                Generate Analytical TTS Script
            </button>
        </div>
    
      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        <div className="flex flex-col space-y-4">
          <div className="flex items-center justify-between">
            <h3 className="text-xl font-bold text-purple-400">TTS Pro Script Editor</h3>
            {editableScript && (
              <button
                onClick={() => downloadText(editableScript, `script-${createTimestamp()}.txt`)}
                className="flex items-center px-3 py-1 text-sm bg-gray-700 hover:bg-gray-600 rounded-md transition-colors"
                title="ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ"
              >
                <IconDownload className="w-4 h-4 mr-1" />
                ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
              </button>
            )}
          </div>
          <div className="flex-grow flex flex-col bg-gray-800/50 p-4 rounded-lg">
            <textarea
              value={editableScript}
              onChange={(e) => setEditableScript(e.target.value)}
              className="w-full flex-grow bg-transparent border border-gray-600 rounded-md p-2 focus:outline-none focus:ring-2 focus:ring-purple-500 font-mono text-sm"
              placeholder="Your Gemini TTS Pro optimized script will appear here..."
              rows={10}
            />
             <div className="flex flex-col sm:flex-row gap-2 mt-4">
                <button onClick={handleOptimizeScript} disabled={!editableScript} className="flex-1 flex items-center justify-center px-4 py-2 font-semibold bg-blue-600 rounded-md hover:bg-blue-700 transition-colors disabled:bg-gray-600 disabled:cursor-not-allowed">
                  <IconSparkles className="w-5 h-5 mr-2" />
                  Optimize for Podcast Delivery
                </button>
                <button onClick={handleGenerateConversation} disabled={!editableScript} className="flex-1 flex items-center justify-center px-4 py-2 font-semibold bg-purple-600 rounded-md hover:bg-purple-700 transition-colors disabled:bg-gray-600 disabled:cursor-not-allowed" title="Flash ëª¨ë¸ë¡œ Multi-speaker ì „ì²´ ëŒ€í™”ë¥¼ í•˜ë‚˜ì˜ ì˜¤ë””ì˜¤ë¡œ ìƒì„± (ìµœëŒ€ 8ë¶„ ì†Œìš”)">
                  <IconAudio className="w-5 h-5 mr-2" />
                  Full Conversation (Flash/ì•ˆì •)
                </button>
                <button onClick={handleGenerateQVoice} disabled={!editableScript || audioData.q} className="flex-1 flex items-center justify-center px-4 py-2 font-semibold bg-blue-600 rounded-md hover:bg-blue-700 transition-colors disabled:bg-gray-600 disabled:cursor-not-allowed" title={audioData.q ? "Q ìŒì„±ì´ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤" : "Q ë¶„ì„ê°€ ìŒì„±ë§Œ ê°œë³„ ìƒì„±"}>
                  <IconAudio className="w-5 h-5 mr-2" />
                  Q Voice (Flash)
                </button>
                <button onClick={handleGenerateJiyoungVoice} disabled={!editableScript || audioData.jiyoung} className="flex-1 flex items-center justify-center px-4 py-2 font-semibold bg-green-600 rounded-md hover:bg-green-700 transition-colors disabled:bg-gray-600 disabled:cursor-not-allowed" title={audioData.jiyoung ? "ì§€ì˜ ìŒì„±ì´ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤" : "ì§€ì˜ í˜¸ìŠ¤íŠ¸ ìŒì„±ë§Œ ê°œë³„ ìƒì„±"}>
                  <IconAudio className="w-5 h-5 mr-2" />
                  ì§€ì˜ Voice (Flash)
                </button>
             </div>
          </div>
        </div>

        <div className="space-y-4">
            <h3 className="text-xl font-bold text-purple-400">Audio Tracks</h3>
            <ConversationPlayer audio={conversationAudio} />
            {personas.map(p => <AudioPlayer key={p.id} persona={p} audio={audioData[p.id]} />)}
        </div>
      </div>
    </div>
  );
};