/**
 * Google Cloud Text-to-Speech ì„œë¹„ìŠ¤
 * 
 * ì‚¬ìš© ì „ ì„¤ì •:
 * 1. Google Cloud Consoleì—ì„œ í”„ë¡œì íŠ¸ ìƒì„±
 * 2. Text-to-Speech API í™œì„±í™”
 * 3. API í‚¤ ë˜ëŠ” ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ë°œê¸‰
 * 4. .env.localì— GOOGLE_CLOUD_API_KEY ì¶”ê°€
 */

interface GoogleCloudTTSRequest {
  input: {
    text: string;
  };
  voice: {
    languageCode: string;
    name?: string;
    ssmlGender?: 'MALE' | 'FEMALE' | 'NEUTRAL';
  };
  audioConfig: {
    audioEncoding: 'LINEAR16' | 'MP3';
    pitch?: number;
    speakingRate?: number;
  };
}

interface GoogleCloudTTSResponse {
  audioContent: string;
}

/**
 * Google Cloud TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± í•©ì„±
 */
export async function synthesizeSpeechGoogleCloud(
  text: string,
  voiceConfig: {
    languageCode?: string;
    name?: string;
    gender?: 'MALE' | 'FEMALE' | 'NEUTRAL';
    pitch?: number;
    speakingRate?: number;
  } = {}
): Promise<string> {
  // Google Cloud API í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ Gemini API í‚¤ ì‚¬ìš©
  const apiKey = process.env.GOOGLE_CLOUD_API_KEY || process.env.GEMINI_API_KEY || process.env.API_KEY;
  
  if (!apiKey) {
    throw new Error('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env.local íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
  }

  console.warn('ğŸ”‘ Using API key:', apiKey.substring(0, 20) + '...');

  const request: GoogleCloudTTSRequest = {
    input: { text },
    voice: {
      languageCode: voiceConfig.languageCode || 'ko-KR',
      name: voiceConfig.name,
      ssmlGender: voiceConfig.gender || 'NEUTRAL'
    },
    audioConfig: {
      audioEncoding: 'LINEAR16',
      pitch: voiceConfig.pitch || 0,
      speakingRate: voiceConfig.speakingRate || 1.0
    }
  };

  try {
    console.warn('ğŸŒ TTS API Request:', {
      url: 'https://texttospeech.googleapis.com/v1/text:synthesize',
      voice: request.voice,
      textLength: text.length
    });

    const response = await fetch(
      `https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(request)
      }
    );

    console.warn('ğŸ“¡ TTS API Response status:', response.status);

    if (!response.ok) {
      const errorData = await response.json();
      console.error('âŒ TTS API Error Response:', errorData);
      
      // 403 Forbidden ìƒì„¸ ë¶„ì„
      if (response.status === 403) {
        const message = errorData.error?.message || '';
        
        if (message.includes('blocked')) {
          throw new Error(
            'âš ï¸ Text-to-Speech APIê°€ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n' +
            'í•´ê²° ë°©ë²•:\n' +
            '1. Google Cloud Consoleì—ì„œ Text-to-Speech APIë¥¼ í™œì„±í™”í•˜ì„¸ìš”\n' +
            '2. API í‚¤ ì œí•œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš” (HTTP ë¦¬í¼ëŸ¬, IP ì œí•œ ë“±)\n' +
            '3. API í‚¤ ì œí•œì—ì„œ "Text-to-Speech API"ë¥¼ í—ˆìš© ëª©ë¡ì— ì¶”ê°€í•˜ì„¸ìš”\n\n' +
            `ì›ë³¸ ì—ëŸ¬: ${message}`
          );
        }
      }
      
      throw new Error(
        errorData.error?.message || 
        `Google Cloud TTS API ì˜¤ë¥˜ (${response.status})`
      );
    }

    const data: GoogleCloudTTSResponse = await response.json();
    return data.audioContent;

  } catch (error) {
    console.error('Google Cloud TTS Error:', error);
    throw error;
  }
}

/**
 * ì‚¬ìš© ê°€ëŠ¥í•œ í•œêµ­ì–´ ìŒì„± ëª©ë¡
 */
export const KOREAN_VOICES = {
  // ë‚¨ì„± ìŒì„±
  MALE_A: { name: 'ko-KR-Neural2-C', gender: 'MALE' as const, description: 'ë‚¨ì„± ìŒì„± A' },
  MALE_B: { name: 'ko-KR-Wavenet-C', gender: 'MALE' as const, description: 'ë‚¨ì„± ìŒì„± B' },
  
  // ì—¬ì„± ìŒì„±
  FEMALE_A: { name: 'ko-KR-Neural2-A', gender: 'FEMALE' as const, description: 'ì—¬ì„± ìŒì„± A' },
  FEMALE_B: { name: 'ko-KR-Wavenet-A', gender: 'FEMALE' as const, description: 'ì—¬ì„± ìŒì„± B' },
  
  // ì¤‘ì„± ìŒì„±
  NEUTRAL: { name: 'ko-KR-Standard-A', gender: 'NEUTRAL' as const, description: 'ì¤‘ì„± ìŒì„±' },
};

/**
 * ë‹¤ì¤‘ í™”ì ëŒ€í™”ë¥¼ ìœ„í•œ TTS ìƒì„±
 * ìŠ¤í¬ë¦½íŠ¸ì—ì„œ "Q:", "ì§€ì˜:" ë“±ì˜ í™”ìë¥¼ ìë™ ê°ì§€í•˜ì—¬ ê°ê¸° ë‹¤ë¥¸ ëª©ì†Œë¦¬ë¡œ í•©ì„±
 */
export async function synthesizeConversation(
  script: string,
  speakerVoices: {
    [speaker: string]: {
      name: string;
      gender: 'MALE' | 'FEMALE' | 'NEUTRAL';
    };
  }
): Promise<Blob[]> {
  // ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™”ìë³„ë¡œ ë¶„ë¦¬
  const lines = script.split('\n');
  const audioSegments: Blob[] = [];

  for (const line of lines) {
    const trimmed = line.trim();
    if (!trimmed) continue;

    // í™”ì ê°ì§€ (ì˜ˆ: "Q:", "ì§€ì˜:")
    const match = trimmed.match(/^([^:]+):\s*(.+)$/);
    if (!match) continue;

    const [, speaker, text] = match;
    const voiceConfig = speakerVoices[speaker.trim()] || speakerVoices['default'];

    if (!voiceConfig) continue;

    // ìŒì„± í•©ì„±
    const audioBase64 = await synthesizeSpeechGoogleCloud(text, {
      languageCode: 'ko-KR',
      ...voiceConfig
    });

    // Base64ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
    const audioData = Uint8Array.from(atob(audioBase64), c => c.charCodeAt(0));
    const blob = new Blob([audioData], { type: 'audio/wav' });
    audioSegments.push(blob);
  }

  return audioSegments;
}

